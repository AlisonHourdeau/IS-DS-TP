title("Histogrammes", outer=TRUE, line=-1,cex.main=1.5)
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(dplyr)
library(plyr)
library(xtable)
library(corrplot)
library(cluster)
library(factoextra)
library(dendextend)
library(ggplot2)
library(data.table)
data = read.csv("Camera.csv", header=TRUE, sep = ";")
dim(data)
nb_indiv <- dim(data)[1]
nb_car <- dim(data)[2]
data_sans_NA = na.omit(data)
summary(data_sans_NA)
data=data_sans_NA
dim(data)
nb_indiv <- dim(data)[1]
nb_car <- dim(data)[2]
data.quanti = data[,cbind(3:13)]
stats_descr = round(sapply(data.quanti, each(min, max, mean, sd, var, median, IQR)),3)
xtable(stats_descr,digits = 2)
boxplot(data.quanti,main='Boxplot des variables quantitatives',cex.main=1,col='grey', las=2)
#standardisation des données
data.quanti.norm <- scale(data.quanti,center=T,scale=T)
l = ncol(data.quanti.norm)
par(mfrow=c(2,3))
for (i in 1:l) {
hist(data.quanti.norm[,i],probability=TRUE,xlab=colnames(data.quanti.norm)[i],main='')
curve(dnorm(x), add=T, col="red", lwd=2, lty=2)
}
title("Histogrammes", outer=TRUE, line=-1,cex.main=1.5)
barplot(table(data$Release.date), main="Nombre d'appareils photos en fonction des années de sortie")
correlations = cor(data.quanti)
corrplot(correlations,method="circle", addCoef.col = "black", diag=FALSE, type="upper", order="hclust", tl.col="black", tl.srt=30)
cluster_by_indiv <- function(indiv, barycentres) {
min <- NULL
cluster <- NULL
for(i in 1:nrow(barycentres)){
indiv_bary <- rbind(indiv,barycentres[i,])
distance <- as.matrix(dist(indiv_bary, method = "euclidean"))[2,1]
if(!is.na(distance) && (min > distance || is.null(min))) {
min <- distance
cluster <- i
}
}
return(cluster)
}
matrices_egales <- function(A, B) {
if( isTRUE(ncol(A) != ncol(B)) ) return(FALSE)
if( isTRUE(nrow(A) != nrow(B)) ) return(FALSE)
for( i in 1:nrow(A) ){
for( j in 1:ncol(A) ) {
if( A[i,j] != B[i,j] ) return(FALSE)
}
}
return(TRUE)
}
haveToStop <- function(i, max_iter, data, old_data){
if(i>=max_iter) return(TRUE)
else return(matrices_egales(as.matrix(data$cluster),as.matrix(old_data$cluster)))
}
algo_Lloyd <- function(k, data) {
#En premier lieu, on vérifie la valeur de k :
nb_indiv <- nrow(data)
if(k<1) {
stop("Le nombre de classes doit être supérieur à 1.")
}
if(k>nb_indiv) {
stop("Le nombre de classes doit être inférieur au nombre d'individus.")
}
# On choisit aléatoirement et sans remise k points parmi les données data
#Ces points seront les barycentres des k classes
barycentres <- data[sample(1:nrow(data),k, replace = FALSE),]
# i : nombre d'itérations, initialisé à 0
i <- 0
# max_iter : nombre d'itérations maximum, initialisé à 100
max_iter <- 5
# stop : booleen indiquant si l'on doit arrêter l'algorithme
# On arrête si une des conditions suivantes est vraie :
# min intra max inter
# 1 - i >= max_iter
# 2 - aucun indiv ne change de classe
# 3 - inertie intra ne diminue plus
# 4 - le vecteur des barycentres est stable
stop <- FALSE
#faire une fonction qui vérifie data cluster != null
cluster <- c()
for(d in 1:nrow(data)){
cluster <- rbind(cluster,-1)
}
data <- cbind(data, cluster)
while(!stop){
old_data <- data
data$cluster <- cluster
if(i>0) {
barycentres <- NULL
for(j in 1:k){
vect_barycentre <- colMeans(
subset(old_data[,-ncol(old_data)],
old_data$cluster == j)
)
barycentres <- rbind(barycentres, vect_barycentre)
}
}
for(j in 1:nrow(data)){
data[j,-1] <- cluster_by_indiv(data[j,-ncol(data)], barycentres)
}
stop <- haveToStop(i, max_iter, data, old_data)
i <- i+1
}
return(data)
}
barycentre<-function(vect){
# apply permet d'appliquer ici la fonction mean aux colonnes de vect.
return(apply(vect,2, mean)) }
distances<-function(vect){
bar <- barycentre(vect) # Calcul du barycentre de l'ensemble de points.
# On le rajoute à l'ensemble des points afin de calculer les distances
# globales avec l'ensemble des points.
vect.2 <- rbind(vect,bar) #
z <- dist(vect.2,method = "euclidean")
return (as.matrix(z))
}
inertie_totale<-function(data){
n <- nrow(data)
res <- sum((distances(data)^2)[n+1,1:n])/n
return(res)
}
inertie_intra<-function(data,k){
n_var=ncol(data)
n=nrow(data)
inertie=c()
effectifs=c()
for(i in 1:k){
donnees_cluster=filter(data,cluster==i)
effectifs[i]=nrow(donnees_cluster)
inertie[i]=inertie_totale(donnees_cluster[,1:n_var])
}
n <- nrow(data)
inertie.intra<-(1/n)*sum(effectifs*inertie)
return(inertie.intra)
}
inertie_inter<-function(data,k){
G=c()
effectifs=c()
ecarts=c()
for(i in 1:k){
donnees_cluster=filter(data,cluster==i)
G=rbind(G,barycentre(donnees_cluster))
effectifs[i]=nrow(donnees_cluster)
}
G=rbind(G,barycentre(data))
nbar <- nrow(G)
ecarts <-(as.matrix(dist(G))^2)[nbar,1:nbar-1]
n<-nrow
res = sum(ecarts*effectifs)/sum(effectifs)
return(res)
}
inertie_expliquee<-function(data,k){
inertie.intra=inertie_intra(data,k)
inertie.totale=inertie_totale(data)
return (round((1-(inertie.intra/inertie.totale))*100,2))
}
result_kImpl <- c()
for (i in 1:5) {
donnees_impl = algo_Lloyd(i,data.quanti)
inter=inertie_inter(donnees_impl,i)
tot=inertie_totale(donnees_impl)
result_kImpl[i]=inter/tot
}
plot(1:5,
result_kImpl,
type='b',
main =
"Représentation de la courbe du R² en fonction du nombre de classes",
xlab="Nombre de classes",
ylab = "Coefficient R²")
dim(data.quanti)
dataLloyd=algo_Lloyd(3,data.quanti)
inertie_intra(dataLloyd,3)
inertie_totale(dataLloyd)
inertie_inter(dataLloyd,3)
inertie_expliquee(dataLloyd,3)
table(dataLloyd$cluster)
result_kMeans <- c()
for (i in 1:10) {
restmp=kmeans(data.quanti,centers=i,algorithm="MacQueen")
result_kMeans[i]=restmp$betweenss/restmp$totss
}
plot(1:10,
result_kMeans,
type='b',
main =
"Représentation de la courbe du R² en fonction du nombre de classes",
xlab="Nombre de classes",
ylab = "Coefficient R²")
fviz_nbclust(data.quanti,kmeans,method="silhouette")
nb_class <- 4
kmeans.2 <- kmeans(data.quanti, centers=nb_class, algorithm=c("Lloyd"))
kmeans.2$totss #inertie totale
kmeans.2$tot.withinss #inertie intra
kmeans.2$betweenss #inertie inter
kable(table(kmeans.2$cluster))
kmeans.2$centers
fviz_cluster (kmeans.2, data.quanti, geom="point")
result_kPam <- c()
for (i in 1:10) {
pam = pam(data.quanti, i, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
inter=inertie_inter(donnees_pam,i)
tot=inertie_totale(donnees_pam)
result_kPam[i]=inter/tot
}
plot(1:10,
result_kPam,
type='b',
main =
"Représentation de la courbe du R² en fonction du nombre de classes",
xlab="Nombre de classes",
ylab = "Coefficient R²")
fviz_nbclust(data.quanti,cluster::pam,method = "silhouette")
k=2
pam = pam(data.quanti, k, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
inertie_intra(donnees_pam,k)
inertie_totale(donnees_pam)
inertie_inter(donnees_pam,k)
inertie_expliquee(donnees_pam,k)
table(donnees_pam$cluster)
pam$medoids # objets qui représentent les centres de classes.
k=3
pam = pam(data.quanti, k, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
inertie_intra(donnees_pam,k)
inertie_totale(donnees_pam)
inertie_inter(donnees_pam,k)
inertie_expliquee(donnees_pam,k)
fviz_cluster (pam, data.quanti, geom="point")
fviz_silhouette(silhouette(pam))
result_kClara <- c()
for (i in 1:10) {
clara = clara(data.quanti, i, metric = "euclidean")
donnees_clara=cbind(data.quanti,clara$clustering)
setnames(donnees_clara, "clara$clustering", "cluster")
inter=inertie_inter(donnees_clara,i)
tot=inertie_totale(donnees_clara)
result_kClara[i]=inter/tot
}
plot(1:10,
result_kClara,
type='b',
main =
"Représentation de la courbe du R² en fonction du nombre de classes",
xlab="Nombre de classes",
ylab = "Coefficient R²")
fviz_nbclust(data.quanti,cluster::clara,method="silhouette")
k=2
clara = clara(data.quanti, k, metric = "euclidean") # samples par défaut : 5
donnees_clara=cbind(data.quanti,clara$clustering)
setnames(donnees_clara, "clara$clustering", "cluster")
inertie_intra(donnees_clara,k)
inertie_totale(donnees_clara)
inertie_inter(donnees_clara,k)
inertie_expliquee(donnees_clara,k)
table(donnees_clara$cluster)
clara$medoids
fviz_cluster (clara, data.quanti, geom="point")
fviz_silhouette(silhouette(clara))
CAH <- hclust(dist(data.quanti,method = 'euclidian'), method='ward.D2')
CAH
fviz_nbclust(data.quanti,factoextra::hcut,method="silhouette")
h <- CAH$height
plot(
(nrow(data.quanti)-1):1,
h,
xlab="nb groupes",
ylab="augmentation inertie_intra",
type="h")
ggplot(color_branches(CAH, k = 3), labels = FALSE)
groupes.cah <- cutree(CAH,k=3)
table(groupes.cah)
groupes.cah <- cutree(CAH,k=3)
donnees_cah=cbind(data.quanti,groupes.cah)
setnames(donnees_cah, "groupes.cah", "cluster")
inertie_intra(donnees_cah,3)
inertie_totale(donnees_cah)
inertie_inter(donnees_cah,3)
inertie_expliquee(donnees_cah,3)
X=c()
k=3
dataLloyd=algo_Lloyd(k,data.quanti)
vect=c(
"Méthode Lloyd implémentée",
round(inertie_intra(dataLloyd,k),0),
round(inertie_totale(dataLloyd),0),
round(inertie_inter(dataLloyd,k),0),
round(inertie_expliquee(dataLloyd,k),2))
X=rbind(X,vect)
kmeans.2 <- kmeans(data.quanti, centers=k, algorithm=c("Lloyd"))
inertie.expliquee=round((1-(kmeans.2$tot.withinss/kmeans.2$totss))*100,2)
vect=c(
"Méthode Lloyd de R",
round(kmeans.2$tot.withinss),
round(kmeans.2$totss),
round(kmeans.2$betweenss)
,round(inertie.expliquee))
X=rbind(X,vect)
pam = pam(data.quanti, k, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
vect=c(
"Méthode PAM",
round(inertie_intra(donnees_pam,k),0),
round(inertie_totale(donnees_pam),0),
round(inertie_inter(donnees_pam,k),0),
round(inertie_expliquee(donnees_pam,k),2))
X=rbind(X,vect)
clara = clara(data.quanti, k, metric = "euclidean") # samples par défaut : 5
donnees_clara=cbind(data.quanti,clara$clustering)
setnames(donnees_clara, "clara$clustering", "cluster")
vect=c(
"Méthode Clara",
round(inertie_intra(donnees_clara,k),0),
round(inertie_totale(donnees_clara),0),
round(inertie_inter(donnees_clara,k),0),
round(inertie_expliquee(donnees_clara,k),2))
X=rbind(X,vect)
groupes.cah <- cutree(CAH,k)
donnees_cah=cbind(data.quanti,groupes.cah)
setnames(donnees_cah, "groupes.cah", "cluster")
vect=c(
"Méthode CAH",
round(inertie_intra(donnees_cah,k),0),
round(inertie_totale(donnees_cah),0),
round(inertie_inter(donnees_cah,k),0),
round(inertie_expliquee(donnees_cah,k),2))
X=rbind(X,vect)
colnames(X)=c("Méthode de classification","Inertie Intra","Inertie Totale","Inertie Inter","Inertie Expliquée")
kable(X)
nb_class <- 4
kmeans.2 <- kmeans(data.quanti, centers=nb_class, algorithm=c("Lloyd"))
nb_class <- 4
kmeans.2 <- kmeans(data.quanti, centers=nb_class, algorithm=c("Lloyd"))
kmeans.2$totss #inertie totale
kmeans.2$tot.withinss #inertie intra
kmeans.2$betweenss #inertie inter
kable(table(kmeans.2$cluster))
kmeans.2$centers
dim(data.quanti)
dataLloyd=algo_Lloyd(3,data.quanti)
inertie_intra(dataLloyd,3)
inertie_totale(dataLloyd)
inertie_inter(dataLloyd,3)
inertie_expliquee(dataLloyd,3)
table(dataLloyd$cluster)
result_kMeans <- c()
for (i in 1:10) {
restmp=kmeans(data.quanti,centers=i,algorithm="MacQueen")
result_kMeans[i]=restmp$betweenss/restmp$totss
}
plot(1:10,
result_kMeans,
type='b',
main =
"Représentation de la courbe du R² en fonction du nombre de classes",
xlab="Nombre de classes",
ylab = "Coefficient R²")
fviz_nbclust(data.quanti,kmeans,method="silhouette")
nb_class <- 4
kmeans.2 <- kmeans(data.quanti, centers=nb_class, algorithm=c("Lloyd"))
nb_class <- 4
kmeans.2 <- kmeans(data.quanti, centers=nb_class, algorithm=c("Lloyd"))
kmeans.2$totss #inertie totale
kmeans.2$tot.withinss #inertie intra
kmeans.2$betweenss #inertie inter
kable(table(kmeans.2$cluster))
kmeans.2$centers
fviz_cluster (kmeans.2, data.quanti, geom="point")
result_kPam <- c()
for (i in 1:10) {
pam = pam(data.quanti, i, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
inter=inertie_inter(donnees_pam,i)
tot=inertie_totale(donnees_pam)
result_kPam[i]=inter/tot
}
plot(1:10,
result_kPam,
type='b',
main =
"Représentation de la courbe du R² en fonction du nombre de classes",
xlab="Nombre de classes",
ylab = "Coefficient R²")
fviz_nbclust(data.quanti,cluster::pam,method = "silhouette")
k=2
pam = pam(data.quanti, k, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
inertie_intra(donnees_pam,k)
inertie_totale(donnees_pam)
inertie_inter(donnees_pam,k)
inertie_expliquee(donnees_pam,k)
table(donnees_pam$cluster)
pam$medoids # objets qui représentent les centres de classes.
k=3
pam = pam(data.quanti, k, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
inertie_intra(donnees_pam,k)
inertie_totale(donnees_pam)
inertie_inter(donnees_pam,k)
inertie_expliquee(donnees_pam,k)
fviz_cluster (pam, data.quanti, geom="point")
fviz_silhouette(silhouette(pam))
result_kClara <- c()
for (i in 1:10) {
clara = clara(data.quanti, i, metric = "euclidean")
donnees_clara=cbind(data.quanti,clara$clustering)
setnames(donnees_clara, "clara$clustering", "cluster")
inter=inertie_inter(donnees_clara,i)
tot=inertie_totale(donnees_clara)
result_kClara[i]=inter/tot
}
plot(1:10,
result_kClara,
type='b',
main =
"Représentation de la courbe du R² en fonction du nombre de classes",
xlab="Nombre de classes",
ylab = "Coefficient R²")
fviz_nbclust(data.quanti,cluster::clara,method="silhouette")
k=2
clara = clara(data.quanti, k, metric = "euclidean") # samples par défaut : 5
donnees_clara=cbind(data.quanti,clara$clustering)
setnames(donnees_clara, "clara$clustering", "cluster")
inertie_intra(donnees_clara,k)
inertie_totale(donnees_clara)
inertie_inter(donnees_clara,k)
inertie_expliquee(donnees_clara,k)
table(donnees_clara$cluster)
clara$medoids
fviz_cluster (clara, data.quanti, geom="point")
fviz_silhouette(silhouette(clara))
CAH <- hclust(dist(data.quanti,method = 'euclidian'), method='ward.D2')
CAH
fviz_nbclust(data.quanti,factoextra::hcut,method="silhouette")
groupes.cah <- cutree(CAH,k=3)
donnees_cah=cbind(data.quanti,groupes.cah)
setnames(donnees_cah, "groupes.cah", "cluster")
inertie_intra(donnees_cah,3)
inertie_totale(donnees_cah)
inertie_inter(donnees_cah,3)
inertie_expliquee(donnees_cah,3)
X=c()
k=3
dataLloyd=algo_Lloyd(k,data.quanti)
vect=c(
"Méthode Lloyd implémentée",
round(inertie_intra(dataLloyd,k),0),
round(inertie_totale(dataLloyd),0),
round(inertie_inter(dataLloyd,k),0),
round(inertie_expliquee(dataLloyd,k),2))
X=rbind(X,vect)
kmeans.2 <- kmeans(data.quanti, centers=k, algorithm=c("Lloyd"))
inertie.expliquee=round((1-(kmeans.2$tot.withinss/kmeans.2$totss))*100,2)
vect=c(
"Méthode Lloyd de R",
round(kmeans.2$tot.withinss),
round(kmeans.2$totss),
round(kmeans.2$betweenss)
,round(inertie.expliquee))
X=rbind(X,vect)
pam = pam(data.quanti, k, metric = "euclidean")
donnees_pam=cbind(data.quanti,pam$clustering)
setnames(donnees_pam, "pam$clustering", "cluster")
vect=c(
"Méthode PAM",
round(inertie_intra(donnees_pam,k),0),
round(inertie_totale(donnees_pam),0),
round(inertie_inter(donnees_pam,k),0),
round(inertie_expliquee(donnees_pam,k),2))
X=rbind(X,vect)
clara = clara(data.quanti, k, metric = "euclidean") # samples par défaut : 5
donnees_clara=cbind(data.quanti,clara$clustering)
setnames(donnees_clara, "clara$clustering", "cluster")
vect=c(
"Méthode Clara",
round(inertie_intra(donnees_clara,k),0),
round(inertie_totale(donnees_clara),0),
round(inertie_inter(donnees_clara,k),0),
round(inertie_expliquee(donnees_clara,k),2))
X=rbind(X,vect)
groupes.cah <- cutree(CAH,k)
donnees_cah=cbind(data.quanti,groupes.cah)
setnames(donnees_cah, "groupes.cah", "cluster")
vect=c(
"Méthode CAH",
round(inertie_intra(donnees_cah,k),0),
round(inertie_totale(donnees_cah),0),
round(inertie_inter(donnees_cah,k),0),
round(inertie_expliquee(donnees_cah,k),2))
X=rbind(X,vect)
colnames(X)=c("Méthode de classification","Inertie Intra","Inertie Totale","Inertie Inter","Inertie Expliquée")
kable(X)
